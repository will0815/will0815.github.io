<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
  <meta name="description" content="Will go, Just do it.">
  <meta name="author" content="Will.Quan">
  <meta name="keywords" content="Will go, Just do it., willgo, 最好的从未错过, Will.Quan">
  <title>Will go, Just do it.</title>
  <link rel="canonical" href="index.html">
  <link rel="icon" href="/res/img/favicon.ico" type="image/x-icon">
  <link rel="shortcut icon" href="/res/img/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" href="/res/css/public.css">
  <link rel="stylesheet" href="/res/css/light.css">
  <script src="/res/js/light.js"></script>
  <script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fda48b6233123178f300913a0e707883e' type='text/javascript'%3E%3C/script%3E"));
</script>

</head>
<body>
  <div id="blog">
    <div class="sidebar">
  <div class="profilepic">
    <a href="/"><img src="/res/img/icon.png" alt="logo"></img></a>
  </div>
  <h1 class="title"><a href="/">willgo</a></h1>
  <h2 class="sub-title">最好的从未错过</h2>
  <nav id="nav">
    <ul>
    
      <li><a href="/page/timing.html"><i class="fa fa-clock-o"></i>&nbsp;资料时间</a></li>
    
      <li><a href="/page/category.html"><i class="fa fa-tags"></i>&nbsp;文章分类</a></li>
    
      <li><a href="/page/read.html"><i class="fa fa-book"></i>&nbsp;逗绊读书</a></li>
    
      <li><a href="/page/life.html"><i class="fa fa-eyedropper"></i>&nbsp;生活记录</a></li>
    
      <li><a href="/page/about.html"><i class="fa fa-paper-plane-o"></i>&nbsp;假装关于</a></li>
    
    </ul>
  </nav>  
  <nav id="sub-nav">
    <a class="weibo " href="http://weibo.com/u/2369015654" title="新浪微博" target="_blank"><i class="fa fa-weibo"></i></a>
    <a class="github" href="https://github.com/will0815/" title="GitHub" target="_blank"><i class="fa fa-github fa-2x"></i></a>
    <a class="rss" href="/page/feed.xml" title="RSS订阅" target="_blank"><i class="fa fa-rss"></i></a>
  </nav>
  <div id="license">
    <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" target="_blank" title="本站所有作品采用：&#10;知识共享《署名 非商业性使用 相同方式共享 3.0》&#10;进行许可" >
    <img alt="License" height="31" width="88" src="/res/img/license.png" /></a>
  </div>
</div>

    <div class="main">
        <div style="font-family: segoepr;font-size: 40px;
              margin-top:-5px; color:#fff;">
            <script type="text/javascript" 
            src="http://open.iciba.com/ds_open.php?id=11519&name=willgo&auth=BE45CDE6481CC46336529A1B407855B1" charset="utf-8">
            </script>
        </div>
    
<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/hbase-import-export.html">hbase import export</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#hadoop">hadoop</a>
      </p>
    </header>
    <div class="post-main">
      <ol>
  <li>
    <p>导出HFlie
使用org.apache.hadoop.hbase.mapreduce.Export类
参数: MR配置参数 需导出的表 导出路径 时间戳版本（默认为1）时间戳起始结束时间 可加正则的RowFilter或PrefixFilter</p>

    <pre><code> Export [-D &lt;property=value&gt;]* &lt;tablename&gt; &lt;outputdir&gt; [&lt;versions&gt; [&lt;starttime&gt; [&lt;endtime&gt;]] [^[regex pattern] or [Prefix] to filter]]
 Note: -D properties will be applied to the conf used.
 For example:
 -D mapred.output.compress=true
 -D mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec
 -D mapred.output.compression.type=BLOCK
 Additionally, the following SCAN properties can be specified
 to control/limit what is exported..
 -D hbase.mapreduce.scan.column.family=&lt;familyName&gt;
 -D hbase.mapreduce.include.deleted.rows=true
 For performance consider the following properties:
 -Dhbase.client.scanner.caching=100
 -Dmapred.map.tasks.speculative.execution=false
 -Dmapred.reduce.tasks.speculative.execution=false
 可直接运行也可以利用Driver如：
 hbase org.apache.hadoop.hbase.mapreduce.Driver export &lt;hbase 表&gt; &lt;导出路径&gt;
 hbase org.apache.hadoop.hbase.mapreduce.Driver export my_table /tmp/my_file
</code></pre>
  </li>
  <li>
    <p>导入HFlie</p>

    <pre><code> 使用org.apache.hadoop.hbase.mapreduce.Import类
 参数: Import [options] &lt;tablename&gt; &lt;inputdir&gt;
 By default Import will load data directly into HBase. To instead generate
 HFiles of data to prepare for a bulk data load, pass the option:
 -Dimport.bulk.output=/path/for/output
 For performance consider the following options:
 -Dmapred.map.tasks.speculative.execution=false
 -Dmapred.reduce.tasks.speculative.execution=false
 可直接运行也可以用Driver如：
 hbase org.apache.hadoop.hbase.mapreduce.Driver import &lt;hbase 表&gt; &lt;导入路径&gt;
 hbase org.apache.hadoop.hbase.mapreduce.Driver import my_table /tmp/my_file
</code></pre>
  </li>
  <li>
    <p>批量导入HFlie（导入到已存在的表）</p>

    <pre><code> org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles
 参数: completebulkload &lt;/path/to/hfileoutputformat-output&gt; &lt;tablename&gt;
 可直接运行也可以用Driver如：
 hbase org.apache.hadoop.hbase.mapreduce.Driver completebulkload &lt;导入路径&gt; &lt;hbase 表&gt;
 hbase org.apache.hadoop.hbase.mapreduce.Driver completebulkload /tmp/my_file my_table
</code></pre>

    <p>后面几个工具MR没有测试：</p>
  </li>
  <li>
    <p>导入TSV文件</p>

    <pre><code> org.apache.hadoop.hbase.mapreduce.ImportTsv类
 参数: importtsv -Dimporttsv.columns=a,b,c &lt;tablename&gt; &lt;inputdir&gt;
 必须用-Dimporttsv.columns指定导入的TSV文件的列，列与列之间用逗号隔开
 一个列对应hbase的columnfamily，

 By default importtsv will load data directly into HBase. To instead generate
 HFiles of data to prepare for a bulk data load, pass the option:
 -Dimporttsv.bulk.output=/path/for/output
 Note: if you do not use this option, then the target table must already exist in HBase
 Other options that may be specified with -D include:
 -Dimporttsv.skip.bad.lines=false - fail if encountering an invalid line
 '-Dimporttsv.separator=|' - eg separate on pipes instead of tabs
 -Dimporttsv.timestamp=currentTimeAsLong - use the specified timestamp for the import
 -Dimporttsv.mapper.class=my.Mapper - A user-defined Mapper to use instead of org.apache.hadoop.hbase.mapreduce.TsvImporterMapper
 For performance consider the following options:
 -Dmapred.map.tasks.speculative.execution=false
 -Dmapred.reduce.tasks.speculative.execution=false
 可直接运行也可以用Driver如：
 hbase org.apache.hadoop.hbase.mapreduce.Driver importtsv Dimporttsv.columns=name,age &lt;hbase 表&gt; &lt;导入路径&gt;
 hbase org.apache.hadoop.hbase.mapreduce.Driver importtsv Dimporttsv.columns=name,age my_table /tmp/my_tsvFile
</code></pre>
  </li>
  <li>
    <p>表复制</p>

    <p>org.apache.hadoop.hbase.mapreduce.CopyTable类</p>

    <p>Usage: CopyTable [general options] [–starttime=X] [–endtime=Y] [–new.name=NEW] [–peer.adr=ADR] <tablename>
 Options:
 rs.class hbase.regionserver.class of the peer cluster
 specify if different from current cluster
 rs.impl hbase.regionserver.impl of the peer cluster
 starttime beginning of the time range (unixtime in millis)
 without endtime means from starttime to forever
 endtime end of the time range. Ignored if no starttime specified.
 versions number of cell versions to copy
 new.name new table's name
 peer.adr Address of the peer cluster given in the format
 hbase.zookeeer.quorum:hbase.zookeeper.client.port:zookeeper.znode.parent
 families comma-separated list of families to copy
 To copy from cf1 to cf2, give sourceCfName:destCfName.
 To keep the same name, just give "cfName"
 all.cells also copy delete markers and deleted cells
 Args:
 tablename Name of the table to copy
 Examples:
 To copy 'TestTable' to a cluster that uses replication for a 1 hour window:
 $ bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable
 --starttime=1265875194289
 --endtime=1265878794289
 --peer.adr=server1,server2,server3:2181:/hbase
 --families=myOldCf:myNewCf,cf2,cf3 TestTable
 For performance consider the following general options:
 -Dhbase.client.scanner.caching=100
 -Dmapred.map.tasks.speculative.execution=false</tablename></p>
  </li>
  <li>
    <p>Compares the data</p>

    <p>org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication类
 Usage: verifyrep [–starttime=X] [–stoptime=Y] [–families=A] <peerid> <tablename>
 Options:
 starttime beginning of the time range
 without endtime means from starttime to forever
 stoptime end of the time range
 families comma-separated list of families to copy
 Args:
 peerid Id of the peer used for verification, must match the one given for replication
 tablename Name of the table to verify
 Examples:
 To verify the data replicated from TestTable for a 1 hour window with peer #5
 $ bin/hbase org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication --starttime=1265875194289 --stoptime=1265878794289 5 TestTable</tablename></peerid></p>
  </li>
</ol>

<p>实例记录：</p>

<ol>
  <li>Export Production HBase table as following:
hbase org.apache.hadoop.hbase.mapreduce.Export ‘mytable’ /hbase_bak/mytable</li>
  <li>
    <p>Copy HDFS files to local:
hadoop fs -copyToLocal /hbase_bak/mytable /home/user/hbase_bak/mytable</p>
  </li>
  <li>
    <p>Copy the local files from production to production extension server</p>
  </li>
  <li>Copy local file to HDFS:
hadoop fs -copyFromLocal /home/user/hbase_bak/mytable /hbase_bak/mytable</li>
  <li>Create table in production extension
create ‘mytable’, {NAME=&gt;’log’, VERSION=&gt; 1}</li>
  <li>Import the HDFS files into HBase:
hbase org.apache.hadoop.hbase.mapreduce.Import ‘mytable’ /hbase_bak/mytable</li>
  <li>Verify the result:
hbase shell
count mytable</li>
</ol>

<p>Find both the row count are same in production and production extension.</p>


      <div class="readall"><a href="/blog/2014/09/27/hbase-import-export.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/eclipse-hadoop-job.html">eclipse hadoop job</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#hadoop">hadoop</a>
      </p>
    </header>
    <div class="post-main">
      <p>使用EJob提交jar
在run中添加：</p>

<pre><code>     conf.set("fs.default.name", "hdfs://192.168.241.7:9000");
      conf.set("mapred.job.tracker", "192.168.241.7:9001");
      Job job = new Job(conf, "....... my  job ......");
      try {
        File jarFile = EJob.createTempJar("bin");
        ((JobConf) job.getConfiguration()).setJar(jarFile.toString());
    } catch (IOException e) {
        throw new IOException(e);
    }
</code></pre>

<p>修改hadoop的hdfs-site.xml 关闭权限校验</p>

<pre><code> &lt;property&gt; 
      &lt;name&gt;dfs.permissions&lt;/name&gt; 
      &lt;value&gt;false&lt;/value&gt; 
 &lt;/property&gt; 
</code></pre>

<p><strong>其他解决办法：</strong></p>

<p>hdfs的权限判断十分简单，就是拿发出指令的user name和文件的user name 做比较</p>

  	private void check(INode inode, FsAction access
<pre><code>  ) throws AccessControlException {
if (inode == null) {
  return;
}
FsPermission mode = inode.getFsPermission();

if (user.equals(inode.getUserName())) { //user class
  if (mode.getUserAction().implies(access)) { return; }
}
else if (groups.contains(inode.getGroupName())) { //group class
  if (mode.getGroupAction().implies(access)) { return; }
}
else { //other class
  if (mode.getOtherAction().implies(access)) { return; }
}
throw new AccessControlException("Permission denied: user=" + user
    + ", access=" + access + ", inode=" + inode);
 	 }
}
</code></pre>

<p>在多用户提交任务时遇到Permission denied, 的原因和任务提交的过程有关。</p>

<ol>
  <li>首先提交任务的客户端会把任务相关文件打包放在hadoop.tmp.dir中，这是本地目录，需要通过本地系统权限验证。由于是临时目录直接设置成为777就行.</li>
  <li>
    <p>客户端会将任务文件打包写入hdfs的	</p>

    <pre><code>mapreduce.jobtracker.staging.root.dir + "/" + user + "/.staging" 目录，需要经过hdfs权限验证。通常可以选择两种方法解决。

1) 保持mapreduce.jobtracker.staging.root.dir为默认，将此目录chmod 777
2) 在hdfs的/user目录下建立用户目录，并且chown为该用户，相当于在hdfs下创建一个用户。
然后设置mapreduce.jobtracker.staging.root.dir为/user,  这是官方推荐的，可以看到这个属性的描述是这样写的：
The root of the staging area for users' job files In practice, this should be the directory where users' home directories are located (usually /user)。
3）有人说可以在启动任务时加入hadoop.job.ugi属性指定用户和群组。 我验证这样不行。看源码里也是直接获取
ugi = UserGroupInformation.getCurrentUser();不过看hdfs权限策略这操行应该可以设置。
</code></pre>
  </li>
</ol>


      <div class="readall"><a href="/blog/2014/09/27/eclipse-hadoop-job.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/arraylistarraylink.html">arraylist&arraylink</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#java">java</a>
      </p>
    </header>
    <div class="post-main">
      <p><strong>区别</strong>：</p>

<ol>
  <li>
    <p>array 在定义的时候必须实例化(至少申明大小)，arraylist则可以只是申明</p>

    <ul>
      <li>int[] array = new array[3]</li>
      <li>int[] array = {1,2,3}</li>
      <li>ArrayList arrayList;</li>
      <li>int[] array;则不合法</li>
    </ul>
  </li>
  <li>
    <p>Array只能存储同构对象，ArrayList则可以存储异构对象，当然object[]和使用泛型的arraylist不适用此条。</p>
  </li>
  <li>
    <p>在CRL的托管方式不一样
 Array是连续存储，Arraylist则不一定是连续存储</p>
  </li>
  <li>Array的大小是定义的时候指定的，Arraylist则可以动态扩容</li>
  <li>Array不能随意添加或删除其中的项，ArrayList则可以随意添加删除</li>
</ol>

<p><strong>相似</strong>：</p>

<ol>
  <li>都具有索引，即可以通过索引来直接添加和修改任意项</li>
  <li>所创建的对象都托管在堆中</li>
  <li>都能够对自身进行枚举（因为实现了IEnumerable接口）</li>
</ol>

<p><strong>ArrayList 源码摘要：</strong></p>

<pre><code>1. public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;  
2.         implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable  
3. {  
4.     ......  
5.   
6.     /** 
7.      * The array buffer into which the elements of the ArrayList are stored. 
8.      * The capacity of the ArrayList is the length of this array buffer. 
9.      */  
10.     private transient E[] elementData;  
11.   
12.   
13.     /** 
14.      * The size of the ArrayList (the number of elements it contains). 
15.      * 
16.      * @serial 
17.      */  
18.     private int size;  
19.    ......  
20. }  
21. 
</code></pre>

<p>底层两个属性一个object[] 一个size</p>

<ol>
  <li>ArrayList底层通过object[] 复制的方式（System.arraycopy()）来处理数组的增长</li>
  <li>当ArrayList 的容量不足时，其扩充容量的方式：先将容量扩充至当前容量的1.5倍，若还不够，则将容量扩充至当前需要的数量。</li>
</ol>

<p><strong>ArrayList与Vector的区别</strong></p>

<p>1） vector 是线程同步 的，所以它也是线程安全 的，而arraylist 是线程异步 的，是不安全的 。如果不考虑到线程的安全因素，一般用 arraylist效率比较高。</p>

<p>2） 如果集合中的元素的数目大于目前集合数组的长度时，vector 增长率为目前数组长度的100%, 而arraylist 增长率为目前数组长度的50% .如果在集合中使用数据量比较大的数据，用vector有一定的优势。</p>

<p>3） 如果查找一个指定位置的数据 ，vector和arraylist使用的时间是相同 的，都是O(1) ,这个时候使用vector和arraylist都可以。</p>

<p>而如果移动一个指定位置的数据花费的时间为O(n-i)n为总长度 ，这个时候就应该考虑到使用linklist ,因为它移动一个指定位置的数据所花费的时间为0(1),而查询一个指定位置的数据时花费的时间为0(i)。</p>

<p><strong>ArrayList和LinkedList的大致区别：</strong></p>

<ol>
  <li>ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。</li>
  <li>对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。</li>
  <li>对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 </li>
</ol>

<p><strong>ArrayList和LinkedList在性能上各有优缺点，都有各自所适用的地方，总的说来可以描述如下：</strong></p>

<ol>
  <li>对ArrayList和LinkedList而言，在列表末尾增加一个元素所花的开销都是固定的。对ArrayList而言，主要是在内部数组中增加一项，指向所添加的元素，偶尔可能会导致对数组重新进行分配；而对LinkedList而言，这个开销是统一的，分配一个内部Entry对象。</li>
  <li>在ArrayList的中间插入或删除一个元素意味着这个列表中剩余的元素都会被移动；而在LinkedList的中间插入或删除一个元素的开销是固定的。</li>
  <li>LinkedList不支持高效的随机元素访问。</li>
  <li>ArrayList的空间浪费主要体现在在list列表的结尾预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗相当的空间</li>
</ol>

<p>可以这样说：当操作是在一列数据的后面添加数据而不是在前面或中间,并且需要随机地访问其中的元素时,使用ArrayList会提供比较好的性能；当你的操作是在一列数据的前面或中间添加或删除数据,并且按照顺序访问其中的元素时,就应该使用LinkedList了。</p>


      <div class="readall"><a href="/blog/2014/09/27/arraylistarraylink.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/RegEx.html">RegEx</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#java">java</a>
      </p>
    </header>
    <div class="post-main">
      <p>From: http://www.oschina.net/question/12_9507</p>

<p>元字符
现在你已经知道几个很有用的元字符了，如\b,.,*，还有\d. 正则表达式里还有更多的元字符，比如\s匹配任意的空白 符，包括空格，制表符(Tab)，换行符，中文全角空格等。\w匹配字母或数字或下划线或汉字等。</p>

<p>对中文/汉字的特殊处理是由.Net提供的正则表达式引擎支持的，其它环境下的具体情况请查看 相关文档。</p>

<p>下面来看看更多的例子：</p>

<p>\ba\w<em>\b匹配以字母a开头的单词——先是某个单词开始处(\b)，然后是字 母a,然后是任意数量的字母或数字(\w</em>)， 最后是单词结束处(\b)。</p>

<p>好吧，现在我们说说正则表达式里的单词是什么意思吧：就是不少于一个的连续的\w。不错，这与学习英文时要背的成千上万个同名的东西的确关系不大 :)</p>

<p>\d+匹配1个或更多连续的数字。 这里的+是和<em>类似的元字符，不同的是</em>匹配重复任意次(可能是0次)，而+则匹配重复1次或更多次。</p>

<p>\b\w{6}\b 匹配刚好6个字符的 单词。</p>

<p>表1.常用的元字符
代码	说明
.	匹配除换行符以外的任意字符
\w	匹配字母或数字或下划线或汉字
\s	匹配任意的空白符
\d	匹配数字
\b	匹配单词的开始或结束
^	匹配字符串的开始
$	匹配字符串的结束
正则表达式引擎通常会提供一个“测试指定的字符串是否匹配一个正则表达式”的方法，如JavaScript里的 RegExp.test()方法或.NET里的Regex.IsMatch()方法。这里的匹配是指是字符串里有没有符合表达式规则的部分。如果不使用^和$的话，对于\d{5,12}而言，使用这样的方法就只能保证字符串里包含5到 12连续位数字，而不是整个字符串就是5到12位数字。</p>

<p>元字符^（和数字6在同一个键位上的符号）和$都 匹配一个位置，这和\b有点类似。^匹配你 要用来查找的字符串的开头，$匹配结尾。这两个代码在验证输入的内容时非常有用，比如一个网站如果 要求你填写的QQ号必须为5位到12位数字时，可以使用：^\d{5,12}$。</p>

<p>这里的{5,12}和前面介绍过的{2}是 类似的，只不过{2}匹配只能不多不少重复2次，{5,12}则是重复的次数不能少于5次，不能多于12次， 否则都不匹配。</p>

<p>因为使用了^和$，所以输入 的整个字符串都要用来和\d{5,12}来匹配，也就是说整个输入必须是5到12个数字，因此如果输入的QQ号能匹配这个正则表达式的话，那就符合要求了。</p>

<p>和忽略大小写的选项类似，有些正则表达式处理工具还有一个处理多行的选项。如果选中了这个选项，^和$的意义就变成了匹配行的开始处和结束处。</p>

<p>字符转义
如果你想查找元字符本身的话，比如你查找.,或者*,就出现了问题：你没办法指定它们，因为它们会被解释成别的意思。这时你就得使用\来取消这些字符的特殊意义。因此，你应该使用.和*。当然，要查找\本身，你也得用\.</p>

<p>例如：deerchao.net匹配deerchao.net，C:\Windows匹配C:\Windows。</p>

<p>重复
你已经看过了前面的<em>,+,{2},{5,12}这几个匹配重复的方式了。下面是 正则表达式中所有的限定符(指定数量的代码，例如</em>,{5,12}等)：</p>

<p>表2.常用的限定符
代码/语法	说明
*	重复零次或更多次
+	重复一次或更多次
?	重复零次或一次
{n}	重复n次
{n,}	重复n次或更多次
{n,m}	重复n到m次
下面是一些使用重复的例子：</p>

<p>Windows\d+匹配Windows 后面跟1个或更多数字</p>

<p>^\w+匹配一行的第一个单词(或整个字 符串的第一个单词，具体匹配哪个意思得看选项设置)</p>

<p>字符类
要想查找数字，字母或数字，空白是很简单的，因为已经有了对应这些字符集合的元字符，但是如果你想匹配没有预定义元字符的字符集合(比如元 音字母a,e,i,o,u),应该怎么办？</p>

<p>很简单，你只需要在方括号里列出它们就行了，像[aeiou]就匹配任何一个英文元音字母，[.?!]匹配标点符号(.或?或!)。</p>

<p>我们也可以轻松地指定一个字符范围，像[0-9]代 表的含意与\d就是完全一致的：一位数字； 同理[a-z0-9A-Z_]也完全等同于\w（如 果只考虑英文的话）。</p>

<p>下面是一个更复杂的表达式：(?0\d{2}[) -]?\d{8}。</p>

<p>“(”和“)”也是元字符，后面的分组节里会提 到，所以在这里需要使用转义。</p>

<p>这个表达式可以匹配几种格式的电话号码，像(010)88886666，或022-22334455， 或02912345678等。我们对它进行一些分析吧：首先是一个转义字符(,它能出现0次或1次(?),然后是一个0，后面跟着2个数字(\d{2})，然后是)或-或空格中 的一个，它出现1次或不出现(?)，最后是8个数字(\d{8})。</p>

<p>分枝条件
不幸的是，刚才那个表达式也能匹配010)12345678或(022-87654321这样的“不正确”的格式。要解决这个问题，我们需要用到分枝条件。正则表达式里的分枝条件指的是有几种规则，如 果满足其中任意一种规则都应该当成匹配，具体方法是用|把不同的规则分隔开。听不明白？没关系，看 例子：</p>

<table>
  <tbody>
    <tr>
      <td>0\d{2}-\d{8}</td>
      <td>0\d{3}-\d{7}这个表达式能匹配两种以连字号分隔的电话号码：一种是三位区号，8位本地号(如010-12345678)，一种是4位区号，7位本地号 (0376-2233445)。</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>(0\d{2})[- ]?\d{8}</td>
      <td>0\d{2}[- ]?\d{8}这 个表达式匹配3位区号的电话号码，其中区号可以用小括号括起来，也可以不用，区号与本地号间可以用连字号或空格间 隔，也可以没有间隔。你可以试试用分枝条件把这个表达式扩展成也支持4位区号的。</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>\d{5}-\d{4}</td>
      <td>\d{5}这个表达式用于匹配美国的邮政编码。美国邮编 的规则是5位数字，或者用连字号间隔的9位数字。之所以要给出这个例子是因为它能说明一个问题：使用分枝条件时，要注意各个条件的顺序。 如果你把它改成\d{5}</td>
      <td>\d{5}-\d{4}的话，那么就只会匹配5位的邮编(以及9位邮 编的前5位)。原因是匹配分枝条件时，将会从左到右地测试每个条件，如果满足了某个分枝的话，就不会去再管其它的条件了。</td>
    </tr>
  </tbody>
</table>

<p>分组
我们已经提到了怎么重复单个字符（直接在字符后面加上限定符就行了）；但如果想要重复多个字符又该怎么办？你可以用小括号来指定子表达式(也叫做分组)，然后你就可以指定这个子表达 式的重复次数了，你也可以对子表达式进行其它一些操作(后面会有介绍)。</p>

<p>(\d{1,3}.){3}\d{1,3}是一个简单的IP地址匹配表达式。要理解这个表达式，请按下列顺序分析它：\d{1,3}匹 配1到3位的数字，(\d{1,3}.){3}匹 配三位数字加上一个英文句号(这个整体也就是这个分组)重 复3次，最后再加上一个一到三位的数字(\d{1,3})。</p>

<p>IP地址中每个数字都不能大于255，大家千万不要被《24》第三季的编剧给忽悠了……</p>

<table>
  <tbody>
    <tr>
      <td>不幸的是，它也将匹配256.300.888.999这种不可能存在的IP地 址。如果能使用算术比较的话，或许能简单地解决这个问题，但是正则表达式中并不提供关于数学的任何功能，所以只能使用冗长的分组，选择，字符类来描述一个 正确的IP地址：((2[0-4]\d</td>
      <td>25[0-5]</td>
      <td>[01]?\d\d?).){3}(2[0-4]\d</td>
      <td>25[0-5]</td>
      <td>[01]?\d\d?)。</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>理解这个表达式的关键是理解2[0-4]\d</td>
      <td>25[0-5]</td>
      <td>[01]?\d\d?， 这里我就不细说了，你自己应该能分析得出来它的意义。</td>
    </tr>
  </tbody>
</table>

<p>反义
有时需要查找不属于某个能简单定义的字符类的字符。比如想查找除了数字以外，其它任意字符都行的情况，这时需要用到反义：</p>

<p>表3.常用的反义代码
代码/语法	说明
\W	匹配任意不是字母，数字，下划线，汉字的字符
\S	匹配任意不是空白符的字符
\D	匹配任意非数字的字符
\B	匹配不是单词开头或结束的位置
[^x]	匹配除了x以外的任意字符
[^aeiou]	匹配除了aeiou这几个字母以外的任意字符
例子：\S+匹配不包含空白符的字符串。</p>

<p>&lt;a[^&gt;]+&gt;匹配用 尖括号括起来的以a开头的字符串。</p>

<p>后向引用
使用小括号指定一个子表达式后，匹配这个子表达式的文本(也就是此分组捕获的内容)可以在表达式或其它 程序中作进一步的处理。默认情况下，每个分组会自动拥有一个组号，规则是：从左向右，以分组的左括 号为标志，第一个出现的分组的组号为1，第二个为2，以此类推。</p>

<p>呃……其实,组号分配还不像我刚说得那么简单：</p>

<p>分组0对应整个正则表达式
实际上组号分配过程是要从左向右扫描两遍的：第一遍只给未命名组分配，第二遍只给命名组分配－－因此所有命名组的组号都大于未命名的组 号
你可以使用(?:exp)这样的语法来剥夺一个分组对组号分配的参与权．
后向引用用于重复搜索前面某个分组匹配的文本。例如，\1代表分组1匹配的文本。难以理解？请看示例：</p>

<p>\b(\w+)\b\s+\1\b可以用来匹配重复的单词，像go go, 或者kitty kitty。这个表达式首先是一个单词， 也就是单词开始处和结束处之间的多于一个的字母或数字(\b(\w+)\b)， 这个单词会被捕获到编号为1的分组中，然后是1个或几个空白符(\s+)，最后是分组1中捕获的内容（也就是前面匹配的那个单词）(\1)。</p>

<p>你也可以自己指定子表达式的组名。要指定一个子表达式的组名，请使用这样的语法：(?<word>\w+)(或者把尖括号换成'也 行：(?'Word'\w+)),这样就把\w+的 组名指定为Word了。要反向引用这个分组捕获的 内容，你可以使用\k<word>,所以上一个例子也可以写成这样：\b(?<word>\w+)\b\s+\k<word>\b。</word></word></word></word></p>

<p>使用小括号的时候，还有很多特定用途的语法。下面列出了最常用的一些：</p>

<p>表4.常用分组语法
分类	代码/语法	说明
捕获	(exp)	匹配exp,并捕获文本到自动命名的组里
(?<name>exp)	匹配exp,并捕获文本到名称为name的组里，也可以写成 (?'name'exp)
(?:exp)	匹配exp,不捕获匹配的文本，也不给此分组分配组号
零宽断言	(?=exp)	匹配exp前面的位置
(?&lt;=exp)	匹配exp后面的位置
(?!exp)	匹配后面跟的不是exp的位置
(?&lt;!exp)	匹配前面不是exp的位置
注释	(?#comment)	这种类型的分组不对正则表达式的处理产生任何影响，用于提供注释让人阅 读
我们已经讨论了前两种语法。第三个(?:exp)不会改变正则表达式的处理方式，只 是这样的组匹配的内容不会像前两种那样被捕获到某个组里面，也不会拥有组号。“我为什么会想要这样 做？”——好问题，你觉得为什么呢？</name></p>

<p>零宽断言
地球人，是不是觉得这些术语名称太复杂，太难记了？我也有同感。知道有这么一种东西就行了，它叫什么，随它去 吧！人若无名，便可专心练剑；物若无名，便可随意取舍……</p>

<p>接下来的四个用于查找在某些内容(但并不包括这些内容)之前或之后的东西，也就是说它们像\b,^,$那样用于指定一个位置，这个位置应该满足一定的 条件(即断言)，因此它们也被称为零宽断言。最好还是拿例子来说明吧：</p>

<p>断言用来声明一个应该为真的事实。正则表达式中只有当断言为真时才会继续进行匹配。</p>

<p>(?=exp)也叫零宽度正预测先行断言， 它断言自身出现的位置的后面能匹配表达式exp。比如\b\w+(?=ing\b)， 匹配以ing结尾的单词的前面部分(除了ing以外的部分)，如查找I’m singing while you’re dancing.时，它会匹配sing和danc。</p>

<p>(?&lt;=exp)也叫零宽度正回顾后 发断言，它断言自身出现的位置的前面能匹配表达式exp。比如(?&lt;=\bre)\w+\b会匹配以re开头的单词的后半部 分(除了re以外的部分)，例如在查找reading a book时，它匹配ading。</p>

<p>假如你想要给一个很长的数字中每三位间加一个逗号(当然是从右边加起了)，你可以这样查找需要在前面和里面添加逗号的部分：((?&lt;=\d)\d{3})+\b，用它对1234567890进 行查找时结果是234567890。</p>

<p>下面这个例子同时使用了这两种断言：(?&lt;=\s)\d+(?=\s)匹配以空白符间隔的数字(再次强调，不包括这些空白符)。</p>

<p>负向零宽断言
前面我们提到过怎么查找不是某个字符或不在某个字符类里的字符的方法(反义)。但是如果我们只是想要确 保某个字符没有出现，但并不想去匹配它时怎么办？例如，如果我们想查找这样的单词–它里面出现了字母q,但是q后面跟的不是字母u, 我们可以尝试这样：</p>

<p>\b\w<em>q[^u]\w</em>\b匹配包含后 面不是字母u的字母q的单词。但是如果多做测试(或者你思维足够敏锐，直接就观察出来了)，你会发现，如果q出现在单词 的结尾的话，像Iraq,Benq，这个表达式就会出错。这是因为[^u]总要匹配一个字符，所以如果q是单词的最后一个字符的话，后面的[^u]将 会匹配q后面的单词分隔符(可能是空格，或者是句号或其它的什么)，后面的\w<em>\b将会匹配下一 个单词，于是\b\w</em>q[^u]\w<em>\b就能匹配整个Iraq fighting。负向零宽断言能解决这 样的问题，因为它只匹配一个位置，并不消费任何字符。现在，我们可以这样来解决这个问题：\b\w</em>q(?!u)\w*\b。</p>

<p>零宽度负预测先行断言(?!exp)，断言此位置的后面不能匹配表达式exp。例如：\d{3}(?!\d)匹 配三位数字，而且这三位数字的后面不能是数字；\b((?!abc)\w)+\b匹 配不包含连续字符串abc的单词。</p>

<p>同理，我们可以用(?&lt;!exp),零 宽度负回顾后发断言来断言此位置的前面不能匹配表达式exp：(?&lt;![a-z])\d{7}匹配前面不是小写字母的七位数 字。</p>

<p>请详细分析表达式(?&lt;=&lt;(\w+)&gt;).*(?=&lt;\/\1&gt;)， 这个表达式最能表现零宽断言的真正用途。</p>

<p>一个更复杂的例子：(?&lt;=&lt;(\w+)&gt;).*(?=&lt;\/\1&gt;)匹 配不包含属性的简单HTML标签内里的内容。(&lt;?(\w+)&gt;)指 定了这样的前缀：被尖括号括起来的单词(比 如可能是<b>)，然后是.*(任意的字符串),最后是一个后缀(?=&lt;\/\1&gt;)。注意后缀里的\/，它用到了前面提过的字符转义；\1则是一个反向 引用，引用的正是捕获的第一组，前面的(\w+)匹 配的内容，这样如果前缀实际上是<b>的话，后缀就是</b>了。整个表达式匹配的是<b>和</b> 之间的内容(再次提醒，不包括前缀和后缀本身)。</b></p>

<p>注释
小括号的另一种用途是通过语法(?#comment)来包含注释。例如：2[0-4]\d(?#200-249)|25<a href="?#250-255">0-5</a>|[01]?\d\d?(?#0-199)。</p>

<p>要包含注释的话，最好是启用“忽略模式里的空白符”选项，这样在编写表达式时能任意的添加空格，Tab，换行，而实际使用时这些都将被忽 略。启用这个选项后，在#后面到这一行结束的所有文本都将被当成注释忽略掉。例如，我们可以前面的一个表达式写成这样：</p>

<pre><code>  (?&lt;=    # 断言要匹配的文本的前缀
  &lt;(\w+)&gt; # 查找尖括号括起来的字母或数字(即HTML/XML标签)
  )       # 前缀结束
  .*      # 匹配任意文本
  (?=     # 断言要匹配的文本的后缀
  &lt;\/\1&gt;  # 查找尖括号括起来的内容：前面是一个"/"，后面是先前捕获的标签
  )       # 后缀结束 贪婪与懒惰 当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的 字符。以这个表达式为例：a.*b，它将会匹配最长的以 a开始，以b结束的字符串。如果用它来搜索aabab的话，它会匹配整个字符串aabab。这被称为贪婪匹配。
</code></pre>

<p>有时，我们更需要懒惰匹配，也就是匹配尽可能少的 字符。前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。这样.*?就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提 下使用最少的重复。现在看看懒惰版的例子吧：</p>

<p>a.*?b匹配最短的，以a开始，以b结 束的字符串。如果把它应用于aabab的话，它会匹配aab（第一到第三个字符）和ab（第四到第五个字符）。</p>

<p>为什么第一个匹配是aab（第一到第三个字符）而不是ab（第二到第三个字符）？简单地说，因为正则表达式有另 一条规则，比懒惰／贪婪规则的优先级更高：最先开始的匹配拥有最高的优先权——The match that begins earliest wins。</p>

<p>表5.懒惰限定符
代码/语法	说明
*?	重复任意次，但尽可能少重复
+?	重复1次或更多次，但尽可能少重复
??	重复0次或1次，但尽可能少重复
{n,m}?	重复n到m次，但尽可能少重复
{n,}?	重复n次以上，但尽可能少重复
处理选项
在C#中，你可以使用Regex(String, RegexOptions)构造函数来设置正则表达式的处理选项。 如：Regex regex = new Regex(@”\ba\w{6}\b”, RegexOptions.IgnoreCase);</p>

<p>上面介绍了几个选项如忽略大小写，处理多行等，这些选项能用来改变处理正则表达式的方式。下面是.Net中常用的正则表达式选项：</p>

<p>表6.常用的处理选项
名称	说明
IgnoreCase(忽略大小写)	匹配时不区分大小写。
Multiline(多行模式)	更改^和$的 含义，使它们分别在任意一行的行首和行尾匹配，而不仅仅在整个字符串的开头和结尾匹配。(在此模式下,$的 精确含意是:匹配\n之前的位置以及字符串结束前的位置.)
Singleline(单行模式)	更改.的含义，使它与每一个字符匹配（包括换行 符\n）。
IgnorePatternWhitespace(忽略空白)	忽略表达式中的非转义空白并启用由#标记的注释。
ExplicitCapture(显式捕获)	仅捕获已被显式命名的组。
一个经常被问到的问题是：是不是只能同时使用多行模式和单行模式中的一种？答案是：不是。这两个选项之间没有任何关系，除了它们的名字比较 相似（以至于让人感到疑惑）以外。</p>

<p>平衡组/递归匹配
这里介绍的平衡组语法是由.Net Framework支持的；其它语言／库不一定支持这种功能，或者支持此功能但需要使用不同的语法。</p>

<p>有时我们需要匹配像( 100 * ( 50 + 15 ) )这样的可嵌套的层次性结构， 这时简单地使用(.+)则只会匹配到最左边的左括号和最右边的右括号之间的内容(这里我们讨论 的是贪婪模式，懒惰模式也有下面的问题)。假如原来的字符串里的左括号和右括号出现的次数不相等，比如( 5 / ( 3 + 2 ) ) )，那我们的匹配结果里两者的个数也不会相等。有没有办法在这样的字符串里匹配到最长的，配对的括号之间的 内容呢？</p>

<p>为了避免(和(把你的大脑 彻底搞糊涂，我们还是用尖括号代替圆括号吧。现在我们的问题变成了如何把xx &lt;aa <bbb> <bbb> aa&gt; yy这样的字符串里，最长的配对的尖括号内的内容捕获出来？</bbb></bbb></p>

<p>这里需要用到以下的语法构造：</p>

<p>(?’group’) 把捕获的内容命名为group,并压入堆栈(Stack)
(?’-group’) 从堆栈上弹出最后压入堆栈的名为group的捕获内容，如果堆栈本来为空，则本分组的匹配失败
(?(group)yes|no) 如果堆栈上存在以名为group的捕获内容的话，继续匹配yes部分的表达式，否则继续匹配no部分
(?!) 零宽负向先行断言，由于没有后缀表达式，试图匹配总是失败
如果你不是一个程序员（或者你自称程序员但是不知道堆栈是什么东西），你就这样理解上面的三种语法吧：第一个就 是在黑板上写一个”group”，第二个就是从黑板上擦掉一个”group”，第三个就是看黑板上写的还有没有”group”，如果有就继续匹配yes部 分，否则就匹配no部分。</p>

<p>我们需要做的是每碰到了左括号，就在压入一个”Open”,每碰到一个右括号，就弹出一个，到了最后就看看堆栈是否为空－－如果不为空那就 证明左括号比右括号多，那匹配就应该失败。正则表达式引擎会进行回溯(放弃最前面或最后面的一些字符)，尽量使整个表达式得到匹配。</p>

<p>&lt;                         #最外层的左括号
    [^&lt;&gt;]*                #最外层的左括号后面的不是括号的内容
    (
        (
            (?’Open’&lt;)    #碰到了左括号，在黑板上写一个”Open”
            [^&lt;&gt;]*       #匹配左括号后面的不是括号的内容
        )+
        (
            (?’-Open’&gt;)   #碰到了右括号，擦掉一个”Open”
            [^&lt;&gt;]*        #匹配右括号后面不是括号的内容
        )+
    )*
    (?(Open)(?!))         #在遇到最外层的右括号前面，判断黑板上还有没有没擦掉的”Open”；如果还有，则匹配失败</p>

<blockquote>
  <pre><code>                    #最外层的右括号 平衡组的一个最常见的应用就是匹配HTML,下面这个例子可以匹配嵌套的&lt;div&gt;标签：&lt;div[^&gt;]*&gt;[^&lt;&gt;]*(((?'Open'&lt;div[^&gt;]*&gt;)[^&lt;&gt;]*)+((?'-Open'&lt;/div&gt;)[^&lt;&gt;]*)+)*(?(Open)(?!))&lt;/div&gt;.
</code></pre>
</blockquote>

<p>还有些什么东西没提到
上边已经描述了构造正则表达式的大量元素，但是还有很多没有提到的东西。下面是一些未提到的元素的列表，包含语法和简单的说明。你可以在网 上找到更详细的参考资料来学习它们–当你需要用到它们的时候。如果你安装了MSDN Library,你也可以在里面找到.net下正则表达式详细的文档。</p>

<p>这里的介绍很简略，如果你需要更详细的信息，而又没有在电脑上安装MSDN Library,可以查看关于正则表达式语言元素 的MSDN在线文档。</p>

<p>表7.尚未详细讨论的语法
代码/语法	说明
\a	报警字符(打印它的效果是电脑嘀一声)
\b	通常是单词分界位置，但如果在字符类里使用代表退格
\t	制表符，Tab
\r	回车
\v	竖向制表符
\f	换页符
\n	换行符
\e	Escape
\0nn	ASCII代码中八进制代码为nn的字符
\xnn	ASCII代码中十六进制代码为nn的字符
\unnnn	Unicode代码中十六进制代码为nnnn的字符
\cN	ASCII控制字符。比如\cC代表Ctrl+C
\A	字符串开头(类似^，但不受处理多行选项的影响)
\Z	字符串结尾或行尾(不受处理多行选项的影响)
\z	字符串结尾(类似$，但不受处理多行选项的影响)
\G	当前搜索的开头
\p{name}	Unicode中命名为name的字符类，例如\p{IsGreek}
(?&gt;exp)	贪婪子表达式
(?<x>-<y>exp)	平衡组
(?im-nsx:exp)	在子表达式exp中改变处理选项
(?im-nsx)	为表达式后面的部分改变处理选项
(?(exp)yes|no)	把exp当作零宽正向先行断言，如果在这个位置能匹配，使用yes作为 此组的表达式；否则使用no
(?(exp)yes)	同上，只是使用空表达式作为no
(?(name)yes|no)	如果命名为name的组捕获到了内容，使用yes作为表达式；否则使用 no
(?(name)yes)	同上，只是使用空表达式作为no</y></x></p>

      <div class="readall"><a href="/blog/2014/09/27/RegEx.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/Redis-Java.html">Redis Java简单操作</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#nosql">nosql</a>
      </p>
    </header>
    <div class="post-main">
      <pre><code>import java.util.ArrayList;
import java.util.List;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPool;
import redis.clients.jedis.JedisPoolConfig;
import redis.clients.jedis.JedisShardInfo;
import redis.clients.jedis.ShardedJedis;
import redis.clients.jedis.ShardedJedisPool;

/**
* redis的Java客户端Jedis测试验证
*
* @author
*/
public class Redis {
// 非切片客户端链接
private Jedis jedis;
// 非切片链接池
private JedisPool jedisPool;
// 切片客户端链接
private ShardedJedis shardedJedis;
// 切片链接池
private ShardedJedisPool shardedJedisPool;
// 构造函数
public Redis() {
initialPool();
initialShardedPool();
shardedJedis = shardedJedisPool.getResource();
jedis = jedisPool.getResource();
}

private void initialPool() {
// 池基本配置
JedisPoolConfig config = new JedisPoolConfig();
config.setMaxActive(20);
config.setMaxIdle(5);
config.setMaxWait(1000l);
config.setTestOnBorrow(false);
jedisPool = new JedisPool(config, "localhost", 6379);
}

// 初始化切片池
private void initialShardedPool() {
// 池基本配置
JedisPoolConfig config = new JedisPoolConfig();
config.setMaxActive(20);
config.setMaxIdle(5);
config.setMaxWait(1000l);
config.setTestOnBorrow(false);
// slave链接
List&lt;JedisShardInfo&gt; shards = new ArrayList&lt;JedisShardInfo&gt;();
shards.add(new JedisShardInfo("localhost", 6379, "master"));
// 构造池
shardedJedisPool = new ShardedJedisPool(config, shards);
}

public void show() {
// key检测
testKey();
// string检测
testString();
// list检测
testList();
// set检测
testSet();
// sortedSet检测
testSortedSet();
// hash检测
testHash();
shardedJedisPool.returnResource(shardedJedis);
}

private void testKey() {
System.out.println("=============key==========================");
// 清空数据
System.out.println(jedis.flushDB());
System.out.println(jedis.echo("foo"));
// 判断key否存在
System.out.println(shardedJedis.exists("foo"));
shardedJedis.set("key", "values");
System.out.println(shardedJedis.exists("key"));
}

private void testString() {
System.out.println("=============String========================");
// 清空数据
System.out.println(jedis.flushDB());
// 存储数据
shardedJedis.set("foo", "bar");
System.out.println(shardedJedis.get("foo"));
// 若key不存在，则存储
shardedJedis.setnx("foo", "foo not exits");
System.out.println(shardedJedis.get("foo"));
// 覆盖数据
shardedJedis.set("foo", "foo update");
System.out.println(shardedJedis.get("foo"));
// 追加数据
shardedJedis.append("foo", " hello, world");
System.out.println(shardedJedis.get("foo"));
// 设置key的有效期，并存储数据
shardedJedis.setex("foo", 2, "foo not exits");
System.out.println(shardedJedis.get("foo"));
try {
Thread.sleep(3000);
} catch (InterruptedException e) {
}
System.out.println(shardedJedis.get("foo"));
// 获取并更改数据
shardedJedis.set("foo", "foo update");
System.out.println(shardedJedis.getSet("foo", "foo modify"));
// 截取value的值
System.out.println(shardedJedis.getrange("foo", 1, 3));
System.out.println(jedis.mset("mset1", "mvalue1", "mset2", "mvalue2", "mset3", "mvalue3", "mset4", "mvalue4"));
System.out.println(jedis.mget("mset1", "mset2", "mset3", "mset4"));
System.out.println(jedis.del(new String[] {
"foo", "foo1", "foo3"
}));
}

private void testList() {
System.out.println("=============list==========================");
// 清空数据
System.out.println(jedis.flushDB());
// 添加数据
shardedJedis.lpush("lists", "vector");
shardedJedis.lpush("lists", "ArrayList");
shardedJedis.lpush("lists", "LinkedList");
// 数组长度
System.out.println(shardedJedis.llen("lists"));
// 排序
System.out.println(shardedJedis.sort("lists"));
// 字串
System.out.println(shardedJedis.lrange("lists", 0, 3));
// 修改列表中单个值
shardedJedis.lset("lists", 0, "hello list!");
// 获取列表指定下标的值
System.out.println(shardedJedis.lindex("lists", 1));
// 删除列表指定下标的值
System.out.println(shardedJedis.lrem("lists", 1, "vector"));
// 删除区间以外的数据
System.out.println(shardedJedis.ltrim("lists", 0, 1));
// 列表出栈
System.out.println(shardedJedis.lpop("lists"));
// 整个列表值
System.out.println(shardedJedis.lrange("lists", 0, -1));

}

private void testSet() {
System.out.println("=============set==========================");
// 清空数据
System.out.println(jedis.flushDB());
// 添加数据
shardedJedis.sadd("sets", "HashSet");
shardedJedis.sadd("sets", "SortedSet");
shardedJedis.sadd("sets", "TreeSet");
// 判断value是否在列表中
System.out.println(shardedJedis.sismember("sets", "TreeSet"));;
// 整个列表值
System.out.println(shardedJedis.smembers("sets"));
// 删除指定元素
System.out.println(shardedJedis.srem("sets", "SortedSet"));
// 出栈
System.out.println(shardedJedis.spop("sets"));
System.out.println(shardedJedis.smembers("sets"));
//
shardedJedis.sadd("sets1", "HashSet1");
shardedJedis.sadd("sets1", "SortedSet1");
shardedJedis.sadd("sets1", "TreeSet");
shardedJedis.sadd("sets2", "HashSet2");
shardedJedis.sadd("sets2", "SortedSet1");
shardedJedis.sadd("sets2", "TreeSet1");
// 交集
System.out.println(jedis.sinter("sets1", "sets2"));
// 并集
System.out.println(jedis.sunion("sets1", "sets2"));
// 差集
System.out.println(jedis.sdiff("sets1", "sets2"));
}

private void testSortedSet() {
System.out.println("=============zset==========================");
// 清空数据
System.out.println(jedis.flushDB());
// 添加数据
shardedJedis.zadd("zset", 10.1, "hello");
shardedJedis.zadd("zset", 10.0, ":");
shardedJedis.zadd("zset", 9.0, "zset");
shardedJedis.zadd("zset", 11.0, "zset!");
// 元素个数
System.out.println(shardedJedis.zcard("zset"));
// 元素下标
System.out.println(shardedJedis.zscore("zset", "zset"));
// 集合子集
System.out.println(shardedJedis.zrange("zset", 0, -1));
// 删除元素
System.out.println(shardedJedis.zrem("zset", "zset!"));
System.out.println(shardedJedis.zcount("zset", 9.5, 10.5));
// 整个集合值
System.out.println(shardedJedis.zrange("zset", 0, -1));
}

private void testHash() {
System.out.println("=============hash==========================");
// 清空数据
System.out.println(jedis.flushDB());
//添加数据
shardedJedis.hset("hashs", "entryKey", "entryValue");
shardedJedis.hset("hashs", "entryKey1", "entryValue1");
shardedJedis.hset("hashs", "entryKey2", "entryValue2");
// 判断某个值是否存在
System.out.println(shardedJedis.hexists("hashs", "entryKey"));
// 获取指定的值
System.out.println(shardedJedis.hget("hashs", "entryKey"));
// 批量获取指定的值
System.out.println(shardedJedis.hmget("hashs", "entryKey", "entryKey1"));
// 删除指定的值
System.out.println(shardedJedis.hdel("hashs", "entryKey"));
// 为key中的域 field 的值加上增量 increment
System.out.println(shardedJedis.hincrBy("hashs", "entryKey", 123l));
// 获取所有的keys
System.out.println(shardedJedis.hkeys("hashs"));
// 获取所有的values
System.out.println(shardedJedis.hvals("hashs"));
}

/**
* @param args
*/
public static void main(String[] args){
new Redis().show();
}

}
</code></pre>

      <div class="readall"><a href="/blog/2014/09/27/Redis-Java.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/Page-Block.html">Page Block</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#f2e">f2e</a>
      </p>
    </header>
    <div class="post-main">
      <p>页面block划分</p>

<ol>
  <li>场景分析
一个网站整体布局以及风格一般会保持一致，整个网站各个页面有很多共同的地方，例如整站导航，友情链接等等。我们会看到很多类似下面的页面：</li>
</ol>

<p><img src="/image/page-block.png" alt="" /></p>

<p>如上图我们会发现整个网站中绝大多数页面都会有上面的Header，Left 和footer 这几个部分。这些相同部分无论是前端展示还是后台数据支持都几乎是一致的。如果按照传统开发方式我们开发可能会这样：</p>

<p>（现在有a,b,c三个页面，这三个页面都有上图中left这一部分）首先前端我们可以选择直接code复制或是独立left部分的code在各个要用的地方引用。后台根据request获取数据返回这样的操作同样也是和前端类似的处理方式。</p>

<pre><code>a页面前端：

&lt;div&gt;header page&lt;/div&gt;

。。。。。。

。。。。。。

&lt;div&gt;left page&lt;/div&gt;

。。。。。。

。。。。。。

&lt;div&gt;footer page&lt;/div&gt;

a页面后台：

Aaction{

getDataForHeader(...);

。。。。。。

。。。。。。

getDataForLeft(...);

。。。。。。

。。。。。。

getDataForFooter(...);

。。。。。。

。。。。。。

getDataForASelf(...);

}
</code></pre>

<p>b,c页面的开发与上面雷同，&lt;div&gt;left page&lt;/div&gt;，getDataForLeft(…)这样的代码会在每个页面前后台都会出现。这样我们就会发现left这个区块，其实它是一个内聚型的独立部分（展现+数据），它不需要依赖于所在页面的其它部分，这里我称之为block。</p>

<p>对于这样的场景我们为了提高开发效率提高代码复用性，block我们应该将其与其他部分独立，如将这个页面分为Header，Left，Footer，Main这么几个block，每个block负责自己的展示以及数据的获取最后输出最终的展示html代码，这样他们就完全独立于所在页面，在其他有用到header，left，footer的页面直接在调用对应的block。另外页面分为很多块，其中有些是很少发生变化有些是经常更新的，其实在每次页面request的中，其实是有很多没有必要的后台处理。当这个页面PV量达到一定量时，这样的开销会变得很可观。这时我们可以将这样很少发生变化的block最后输出的html存放在缓存中（如memcache）,从而减少后台处理开销提高网站性能。</p>

<p>实现技术选择：springMVC + freemarker.</p>

<ol>
  <li>技术介绍</li>
</ol>

<p>FreeMarker
What:
<img src="/image/FreeMarker.jpg" alt="" /></p>

<p>Template engine：一个基于Java的模板引擎。
可应用于任何文本类型输出(更多的是用于web应用)
开源项目</p>

<p>Why：</p>

<p>使用template engine来代替JSP, 设计将变得简单，语法更简单，出错信息更易读，工具也更用户化。
template优势（也即jsp的不足）</p>

<ol>
  <li>使前台脱离Java代码</li>
  <li>减少工作量，template更加简洁</li>
  <li>出错信息更加精准
 JSP常有一些让人头疼的出错信息。因为页面首先被转换成为一个servlet然后才进行编译。即使有好的 JSP 工具可以相对增加找到出错位置的可能性，那也是不是一件容易的事儿。
 由于template engine可以在template文件中直接产生而没有任何戏剧性的向代码转化，所以可以非常容易地给出适当的出错报告。</li>
  <li>不依赖编译器
JSP需要一个置放在webserver中的编译器。但这样的编译器并不能在所有平台上顺利工作(用 C++写成的) 也不利于建立纯Java 的web服务器。</li>
  <li>减少空间的浪费
JSP消耗了额外的内存和硬盘空间。对服务器上每30K的JSP文件，必须要有相应的大于30K的类文件产生。实际上使得硬盘空间加倍。考虑到JSP文件随时可以很容易地通过 ＜%@ include＞包含一个大的数据文件。同时，每一个JSP的类文件数据必须加载到服务器的内存中，这意味着服务器的内存必须永远地将整个JSP文档树保存下去。对template engines由于没有产生第二个文件，所以节省了空间。Template engines还为程序员提供对templates</li>
</ol>

<p>在内存中进行缓存的完全控制。</p>

<ol>
  <li>利于实现页面block划分，实现页面的静态化。</li>
</ol>

<p>spring MVC
what：</p>

<p>Spring MVC框架是有一个MVC框架，通过实现Model-View-Controller模式来很好地将数据、业务与展现进行分离。Spring MVC的设计是围绕DispatcherServlet展开的，DispatcherServlet负责将请求派发到特定的handler。通过可配置的handler mappings、view resolution、locale以及theme resolution来处理请求并且转到对应的视图。</p>

<p>Why：</p>

<p>学习难度小于, 小于Struts2.
易于开发性能优秀的程序。
灵活性强，强大扩展性。</p>

<ol>
  <li>实例</li>
</ol>

<p>requirement</p>

<pre><code>功能：实现用户登录显示用户信息
要求：使用freemarker替代jsp,作为view层组件
页面划分为Header，Left，Footer，Main三个block，block间相互独立
模板文件存放在数据库
具备较高的扩展性
易维护
实现技术：springMVC，freemarker, mybatis
</code></pre>

<p>impletement</p>

<p>程序结构图：
 <img src="/image/page-block-impl.png" alt="" /></p>

<p>建立如下工程目录：</p>

<p><img src="/image/page-block-project.png" alt="" /></p>

<p>web.xml：(配置springMVC)</p>

<pre><code>&lt;context-param&gt;

&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;

&lt;param-value&gt;classpath:*Context.xml&lt;/param-value&gt;

&lt;/context-param&gt;

&lt;listener&gt;

&lt;display-name&gt;contextLoaderListener&lt;/display-name&gt;

&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener

&lt;/listener-class&gt;

&lt;/listener&gt;

&lt;listener&gt;

&lt;listener-class&gt;org.springframework.web.context.request.

RequestContextListener

&lt;/listener-class&gt;

&lt;/listener&gt;

&lt;servlet&gt;

&lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;

&lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet

&lt;/servlet-class&gt;

&lt;init-param&gt;

&lt;description&gt;mvc.xml&lt;/description&gt;

&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;

&lt;param-value&gt;classpath:test-mvc.xml&lt;/param-value&gt;

&lt;/init-param&gt;

&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;

&lt;/servlet&gt;

&lt;servlet-mapping&gt;

&lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;

&lt;url-pattern&gt;/&lt;/url-pattern&gt;

&lt;/servlet-mapping&gt;

test-mvc.xml：
&lt;mvc:annotation-driven/&gt;

&lt;!-- 静态的资源文件不要spring的过滤 --&gt;

&lt;mvc:resources mapping="/img/**" location="/img/" /&gt;

&lt;context:component-scan base-package="com.**.controller" /&gt;

&lt;bean id="viewResolver"

class="org.springframework.web.servlet.view.freemarker.FreeMarkerViewRes olver"&gt;

&lt;property name="cache" value="true" /&gt;

&lt;property name="prefix" value="" /&gt;

&lt;property name="suffix" value=".ftl" /&gt;

&lt;property name="contentType" value="text/html;charset=UTF-8" /&gt;

&lt;property name="requestContextAttribute" value="request" /&gt;

&lt;!-- 使用这些宏，必须设置FreeMarkerViewResolver的exposeMacroHelpers属性为true：

在所有需要使用&lt;@spring.bind&gt;和&lt;@spring.bindEscaped&gt;的FreeMarker模板的

顶部增加以下一行：&lt;#import "/spring.ftl" as spring /&gt;

这一行会在模板中导入Spring的FreeMarker宏。

--&gt;

&lt;property name="exposeSpringMacroHelpers" value="true" /&gt;

&lt;!-- 将请求和会话属性作为变量暴露给FreeMarker模板使用 --&gt;

&lt;property name="exposeRequestAttributes" value="true" /&gt;

&lt;property name="exposeSessionAttributes" value="true" /&gt;

&lt;/bean&gt;

在resource中的applicationContext.xml
中配置freemarker和页面所需要的各个block，具体配置如下：
&lt;!-- freemarker 配置 --&gt;

&lt;bean id="freemarkerConfig"

class="org.springframework.web.servlet.view.freemarker.

FreeMarkerConfigurer"&gt;

&lt;property name="templateLoaderPath" value="/WEB-INF/" /&gt;

&lt;property name="freemarkerSettings"&gt;

&lt;props&gt;

&lt;prop key="template_update_delay"&gt;0&lt;/prop&gt;

&lt;prop key="default_encoding"&gt;UTF-8&lt;/prop&gt;

&lt;prop key="number_format"&gt;0.##########&lt;/prop&gt;

&lt;prop key="datetime_format"&gt;yyyy-MM-dd HH:mm:ss&lt;/prop&gt;

&lt;prop key="classic_compatible"&gt;true&lt;/prop&gt;

&lt;prop key="template_exception_handler"&gt;ignore&lt;/prop&gt;

&lt;/props&gt;

&lt;/property&gt;

&lt;/bean&gt;

&lt;!-- 配置各个block,每个block包含对应的ftl模板文件在数据库对应的名字

和freemarkerConfig对象以及其他所需属性 --&gt;

&lt;beanid="baseBlack"abstract="true"&gt;

&lt;property name="freemarkerConfig" ref="freemarkerConfig"/&gt;

&lt;/bean&gt;

&lt;bean id="blockManager" class="com.au.common.BlockManager"

factory-method="getInstance" /&gt;

&lt;bean id="headBlock" class="com.au.cms.block.HeadBlock" parent="baseBlack"&gt;

&lt;property name="template" value="headBlock"&gt;&lt;/property&gt;

&lt;/bean&gt;

&lt;bean id="middleBlock" class="com.au.cms.block.MiddleBlock" parent="baseBlack"&gt;

&lt;property name="template" value="middleBlock"&gt;&lt;/property&gt;

&lt;property name="userDao" ref="userDao"/&gt;

&lt;/bean&gt;

&lt;bean id="footBlock" class="com.au.cms.block.FootBlock" parent="baseBlack"&gt;

&lt;property name="template" value="footBlock"&gt;&lt;/property&gt;

&lt;/bean&gt;
</code></pre>

<p>主要类实现</p>

<p>Controller类：</p>

<pre><code>	@Autowired
	
	private BlockManager blockManager;
	
	@RequestMapping(value = "welcome", method=RequestMethod.GET)
	
	public ModelAndView getFirstPage(HttpServletRequest request) {
	
	ModelAndView mvc = new ModelAndView("layout/welcome");
	
	return mvc;
	
	}
</code></pre>

<p>BlockManager实现一个自定函数用于调用对应的Block并包含show方法如下：</p>

<pre><code>publicclass BlockManager implements TemplateMethodModel {

@SuppressWarnings("rawtypes")

@Override

public Object exec(List args) throws TemplateModelException {

String blockId = args.get(0).toString();

ApplicationContext context = ApplicationContextUtil.getApplicationContext();

HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes())

.getRequest();

if (context.containsBean(blockId)) {

Block block = (Block) context.getBean(blockId);

return block.execute(request);

}

return"";

}

}

AbstractBlock（impletement Block 接口）：

protected String template;

protected FreeMarkerConfigurationFactory freemarkerConfig;

publicvoid setTemplate(String template) {

this.template = template;

}

publicvoid setFreemarkerConfig(FreeMarkerConfigurationFactory freemarkerConfig) {

this.freemarkerConfig = freemarkerConfig;

}

abstractprotected Map&lt;String, Object&gt; preExecute(HttpServletRequest request);

@Override

public String execute(HttpServletRequest request) {

Map&lt;String, Object&gt; map = preExecute(request);

String templateByUser = (String)map.get("BLOCK_TEMPLATE_FILE");

String content = "";

if (templateByUser != null &amp;&amp; !templateByUser.trim().equals("")) {

content = TemplateUtil.process(map, freemarkerConfig, templateByUser);

}

if (templateByUser != null &amp;&amp; templateByUser.trim().equals("")) {

return"";

}

if (templateByUser == null) {

content = TemplateUtil.process(map, freemarkerConfig, template);

}

return postExecute(content);

}

protected String postExecute(String content) {

return content;

}

MiddleBlock（继承AbstractBlock，实现preExcute方法，获取数据）：

@Override

protected Map&lt;String, Object&gt; preExecute(HttpServletRequest request) {

String name = request.getParameter("name");

User user = userDao.getUserByName(name);

Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();

map.put("user", user);

return map;

}

TemplateDataMerge（从数据库取出模板文件merge数据）

Configuration conf = ((FreeMarkerConfigurer) freemarkerConfig).getConfiguration();

FtlSourceDao ftlSourceDao = (FtlSourceDao) ApplicationContextUtil.getApplicationContext().getBean("ftlSourceDao");

FtlSource ftl = ftlSourceDao.getFtlSourceByName(ftlName);

Reader reader = new StringReader(ftl.getFtlSource());

Template template = new Template(ftlName, reader, conf, "UTF-8");

writer = new StringWriter();

template.process(map, writer);

String rs = writer.toString();
</code></pre>

<p>至此程序的主要逻辑已经清楚，其他代码如model,service,dao等就不一一附上。如需要可联系我们</p>

<p>4.测试
访问项目结果如下</p>

<p><img src="/image/page-block-res.png" alt="" /></p>

<p>完。。。</p>


      <div class="readall"><a href="/blog/2014/09/27/Page-Block.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="pagination">
  
  
  <a class="pagination-item newer" href="/page/9"><i class="fa fa-arrow-left"></i>&nbsp;&nbsp;上一页</a>
  
    
  
  <a class="pagination-item older" href="/page/11">下一页&nbsp;&nbsp;<i class="fa fa-arrow-right"></i></a>
  
</div>
    <footer>Copyright&nbsp;&copy;&nbsp;2015 <a href="index.html">willgo</a><br/><i class="fa fa-cogs" style="color:blueviolet;">&nbsp;</i>Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a>
</br> <a href="http://m.kuaidi100.com" target="_blank">快递查询</a> 
</footer>

    </div>
  </div>    
  <div id="top"><a id="rocket" href="javascript:;" title="返回顶部"><i></i></a></div>
  
</body>
</html>
