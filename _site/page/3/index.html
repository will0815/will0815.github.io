<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
  <meta name="description" content="Will go, Just do it.">
  <meta name="author" content="Will.Quan">
  <meta name="keywords" content="Will go, Just do it., willgo, 最好的从未错过, Will.Quan">
  <title>Will go, Just do it.</title>
  <link rel="canonical" href="index.html">
  <link rel="icon" href="/res/img/favicon.ico" type="image/x-icon">
  <link rel="shortcut icon" href="/res/img/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" href="/res/css/public.css">
  <link rel="stylesheet" href="/res/css/light.css">
  <script src="/res/js/light.js"></script>
  <script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Fda48b6233123178f300913a0e707883e' type='text/javascript'%3E%3C/script%3E"));
</script>

</head>
<body>
  <div id="blog">
    <div class="sidebar">
  <div class="profilepic">
    <a href="/"><img src="/res/img/icon.png" alt="logo"></img></a>
  </div>
  <h1 class="title"><a href="/">willgo</a></h1>
  <h2 class="sub-title">最好的从未错过</h2>
  <nav id="nav">
    <ul>
    
      <li><a href="/page/timing.html"><i class="fa fa-clock-o"></i>&nbsp;时间轴</a></li>
    
      <li><a href="/page/category.html"><i class="fa fa-tags"></i>&nbsp;分类</a></li>
    
      <li><a href="/page/read.html"><i class="fa fa-book"></i>&nbsp;阅读</a></li>
    
      <li><a href="/page/read.html"><i class="fa fa-eyedropper"></i>&nbsp;记录</a></li>
    
      <li><a href="/page/about.html"><i class="fa fa-paper-plane-o"></i>&nbsp;关于</a></li>
    
    </ul>
  </nav>  
  <nav id="sub-nav">
    <a class="weibo " href="http://weibo.com/u/2369015654" title="新浪微博" target="_blank"><i class="fa fa-weibo"></i></a>
    <a class="github" href="https://github.com/will0815/will0815.github.io" title="GitHub" target="_blank"><i class="fa fa-github fa-2x"></i></a>
    <a class="rss" href="/page/feed.xml" title="RSS订阅" target="_blank"><i class="fa fa-rss"></i></a>
  </nav>
  <div id="license">
    <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" target="_blank" title="本站所有作品采用：&#10;知识共享《署名 非商业性使用 相同方式共享 3.0》&#10;进行许可" >
    <img alt="License" height="31" width="88" src="/res/img/license.png" /></a>
  </div>
</div>
    <div class="main">
    
<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/hive-.html">hive 安装</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#hadoop">hadoop</a>
      </p>
    </header>
    <div class="post-main">
      <p>Hive安装</p>

<ol>
  <li>
    <p>下载Hive</p>
  </li>
  <li>
    <p>把Hive移动到/home/hadoop目录下并解压</p>

    <pre><code> hadoop@ubuntu:~/下载$ mv hive-0.9.0.tar.gz /home/hadoop/
 hadoop@ubuntu:~$ cd /home/hadoop/
 hadoop@ubuntu:~$ tar -zxvf hive-0.9.0.tar.gz 
</code></pre>
  </li>
  <li>
    <p>用root用户给hive-0.9.0授权</p>

    <pre><code> hadoop@ubuntu:~$ su -
 密码：
 root@ubuntu:~# cd /home/hadoop/
 root@ubuntu:/home/hadoop# sudo chown -R hadoop:hadoop hive-0.9.0
</code></pre>
  </li>
</ol>

<p>4.添加hive-0.9.0环境变量</p>

<pre><code>	/etc/profile
	在以上 文件中添加如下内容：

#set java environment
HIVE_HOME=/home/hadoop/hive-0.9.0
HADOOP_HOME=/home/hadoop/hadoop-1.1.1
JAVA_HOME=/home/hadoop/jdk1.7.0
PATH=$JAVA_HOME/bin:$HIVE_HOME/bin:$HADOOP_HOME/bin:$PATH
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$HIVE_HOME/lib:$JAVA_HOME/lib/tools.jar
export HADOOP_HOME
export JAVA_HOME
export HIVE_HOME
export PATH
export CLASSPATH 
</code></pre>

<ol>
  <li>配置 Hive 配置文件</li>
</ol>

<p>a.配置 hive-conf.sh</p>

<p>在“/home/hadoop/hive-0.9.0/bin”目录下,“hive-conf.sh”,然后在里面添加下面内容。</p>

<pre><code>#set java environment
HIVE_HOME=/home/hadoop/hive-0.9.0
HADOOP_HOME=/home/hadoop/hadoop-1.1.1
JAVA_HOME=/home/hadoop/jdk1.7.0
PATH=$JAVA_HOME/bin:$HIVE_HOME/bin:$HADOOP_HOME/bin:$PATH
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$HIVE_HOME/lib:$JAVA_HOME/lib/tools.jar
export HADOOP_HOME
export JAVA_HOME
export HIVE_HOME
export PATH
export CLASSPATH 
</code></pre>

<p>b.配置 hive-default.xml 和 hive-site.xml</p>

<p>在“/home/hadoop/hive-0.9.0/conf”目录下,没有这两个文件,只有一个“hive-default.xml.template”,所以我们要复制两个“hive-default.xml.template”,并分别命名为“hive-default.xml”和“hive-site.xml” 因为我们当前是 root 用户,。所以还要把两个的文件的授权给 hadoop 用户。</p>

<pre><code>root@ubuntu:/home/hadoop/hive-0.9.0/conf# cp hive-default.xml.template hive-default.xml
root@ubuntu:/home/hadoop/hive-0.9.0/conf# chown -R hadoop:hadoop hive-default.xml
root@ubuntu:/home/hadoop/hive-0.9.0/conf# cp hive-default.xml.template hive-site.xml
root@ubuntu:/home/hadoop/hive-0.9.0/conf# chown -R hadoop:hadoop hive-site.xml
root@ubuntu:/home/hadoop/hive-0.9.0/conf# ls -l
</code></pre>

<p>备注: “hive-default.xml”用于保留默认配置,“hive-site.xml”用于个性化配置,可覆盖默认配置。</p>

<ol>
  <li>启动 Hive</li>
</ol>

<p>此时切换用户至 hadoop 用户,在命令行输入“hive”命令进行测试。</p>

<pre><code>hadoop@ubuntu:~$ hive
WARNING: org.apache.hadoop.metrics.jvm.EventCounter is deprecated. Please use org.apache.hadoop.log.metrics.EventCounter in all the log4j.properties files.
Logging initialized using configuration in jar:file:/home/hadoop/hive-0.9.0/lib/hive-common-0.9.0.jar!/hive-log4j.properties
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201303041031_876597921.txt
hive&gt;
</code></pre>


      <div class="readall"><a href="/blog/2014/09/27/hive-.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/hbaseenable.html">hbase表无法enable</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#hadoop">hadoop</a>
      </p>
    </header>
    <div class="post-main">
      <p>在enable表时，发现耗时很长都未结束，就ctrl+c退出hbase shell，再进入继续enable表，但此时出现如下错误：</p>

<pre><code>ERROR: org.apache.hadoop.hbase.TableNotDisabledException:
</code></pre>

<p>错误说表未禁用，但进行disable表操作时，又出现如下错误：
ERROR: org.apache.hadoop.hbase.TableNotEnabledException
那肯定是刚才强行退出导致出问题了，根据大家的经验，指出这是因为zookeeper保持了要enable的这个表信息，只需要登录zk删除该记录就行。
登录到zookeeper也有两种方式，一是到zk目录运行脚本连接，而是直接在hbase安装目录bin下运行：</p>

<pre><code>hbase zkcli 之后就能连接上zookeeper了，跟着删除/hbase/table下对应的表项就行：

delete /hbase/table/user_video_recommend2 之后就可以成功的enable表了。 如果此时仍然失败，则可以运行一下命了修复META：

hbase hbck -fixMeta -fixAssignments
</code></pre>

      <div class="readall"><a href="/blog/2014/09/27/hbaseenable.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/hbase-time.html">hbase time集群时间不一致无法启动</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#hadoop">hadoop</a>
      </p>
    </header>
    <div class="post-main">
      <p>hbase 分布式时可能因为各个机器的时间不一致导致无法启动
两种解决方案：</p>

<ol>
  <li>
    <p>联网更新时间：</p>

    <pre><code> sudo tzconfig， 如果命令不存在请使用 dpkg-reconfigure tzdata 然后按照提示选择 Asia对应的序号，选完后会显示一堆新的提示—输入城市名， 如Shanghai或Chongqing，最后再用 sudo date -s “” 来修改本地时间。 按照提示进行选择时区，然后： www.2cto.com sudo cp /usr/share/zoneinfo/Asia/ShangHai /etc/localtime 上面的命令是防止系统重启后时区改变。
</code></pre>
  </li>
</ol>

<p>网上同步时间</p>

<ol>
  <li>
    <p>安装ntpdate工具</p>

    <pre><code> # sudo apt-get install ntpdate
</code></pre>
  </li>
  <li>
    <p>设置系统时间与网络时间同步</p>

    <pre><code> # ntpdate cn.pool.ntp.org
</code></pre>
  </li>
  <li>
    <p>将系统时间写入硬件时间</p>

    <p># hwclock –systohc</p>
  </li>
  <li>
    <p>修改hbase的时间检查， 其默认的时间为30000ms</p>

    <pre><code> hbase.master.maxclockskew
 180000
</code></pre>
  </li>
</ol>

      <div class="readall"><a href="/blog/2014/09/27/hbase-time.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/hbase-import-export.html">hbase import export</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#hadoop">hadoop</a>
      </p>
    </header>
    <div class="post-main">
      <ol>
  <li>
    <p>导出HFlie
使用org.apache.hadoop.hbase.mapreduce.Export类
参数: MR配置参数 需导出的表 导出路径 时间戳版本（默认为1）时间戳起始结束时间 可加正则的RowFilter或PrefixFilter</p>

    <pre><code> Export [-D &lt;property=value&gt;]* &lt;tablename&gt; &lt;outputdir&gt; [&lt;versions&gt; [&lt;starttime&gt; [&lt;endtime&gt;]] [^[regex pattern] or [Prefix] to filter]]
 Note: -D properties will be applied to the conf used.
 For example:
 -D mapred.output.compress=true
 -D mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec
 -D mapred.output.compression.type=BLOCK
 Additionally, the following SCAN properties can be specified
 to control/limit what is exported..
 -D hbase.mapreduce.scan.column.family=&lt;familyName&gt;
 -D hbase.mapreduce.include.deleted.rows=true
 For performance consider the following properties:
 -Dhbase.client.scanner.caching=100
 -Dmapred.map.tasks.speculative.execution=false
 -Dmapred.reduce.tasks.speculative.execution=false
 可直接运行也可以利用Driver如：
 hbase org.apache.hadoop.hbase.mapreduce.Driver export &lt;hbase 表&gt; &lt;导出路径&gt;
 hbase org.apache.hadoop.hbase.mapreduce.Driver export my_table /tmp/my_file
</code></pre>
  </li>
  <li>
    <p>导入HFlie</p>

    <pre><code> 使用org.apache.hadoop.hbase.mapreduce.Import类
 参数: Import [options] &lt;tablename&gt; &lt;inputdir&gt;
 By default Import will load data directly into HBase. To instead generate
 HFiles of data to prepare for a bulk data load, pass the option:
 -Dimport.bulk.output=/path/for/output
 For performance consider the following options:
 -Dmapred.map.tasks.speculative.execution=false
 -Dmapred.reduce.tasks.speculative.execution=false
 可直接运行也可以用Driver如：
 hbase org.apache.hadoop.hbase.mapreduce.Driver import &lt;hbase 表&gt; &lt;导入路径&gt;
 hbase org.apache.hadoop.hbase.mapreduce.Driver import my_table /tmp/my_file
</code></pre>
  </li>
  <li>
    <p>批量导入HFlie（导入到已存在的表）</p>

    <pre><code> org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles
 参数: completebulkload &lt;/path/to/hfileoutputformat-output&gt; &lt;tablename&gt;
 可直接运行也可以用Driver如：
 hbase org.apache.hadoop.hbase.mapreduce.Driver completebulkload &lt;导入路径&gt; &lt;hbase 表&gt;
 hbase org.apache.hadoop.hbase.mapreduce.Driver completebulkload /tmp/my_file my_table
</code></pre>

    <p>后面几个工具MR没有测试：</p>
  </li>
  <li>
    <p>导入TSV文件</p>

    <pre><code> org.apache.hadoop.hbase.mapreduce.ImportTsv类
 参数: importtsv -Dimporttsv.columns=a,b,c &lt;tablename&gt; &lt;inputdir&gt;
 必须用-Dimporttsv.columns指定导入的TSV文件的列，列与列之间用逗号隔开
 一个列对应hbase的columnfamily，

 By default importtsv will load data directly into HBase. To instead generate
 HFiles of data to prepare for a bulk data load, pass the option:
 -Dimporttsv.bulk.output=/path/for/output
 Note: if you do not use this option, then the target table must already exist in HBase
 Other options that may be specified with -D include:
 -Dimporttsv.skip.bad.lines=false - fail if encountering an invalid line
 '-Dimporttsv.separator=|' - eg separate on pipes instead of tabs
 -Dimporttsv.timestamp=currentTimeAsLong - use the specified timestamp for the import
 -Dimporttsv.mapper.class=my.Mapper - A user-defined Mapper to use instead of org.apache.hadoop.hbase.mapreduce.TsvImporterMapper
 For performance consider the following options:
 -Dmapred.map.tasks.speculative.execution=false
 -Dmapred.reduce.tasks.speculative.execution=false
 可直接运行也可以用Driver如：
 hbase org.apache.hadoop.hbase.mapreduce.Driver importtsv Dimporttsv.columns=name,age &lt;hbase 表&gt; &lt;导入路径&gt;
 hbase org.apache.hadoop.hbase.mapreduce.Driver importtsv Dimporttsv.columns=name,age my_table /tmp/my_tsvFile
</code></pre>
  </li>
  <li>
    <p>表复制</p>

    <p>org.apache.hadoop.hbase.mapreduce.CopyTable类</p>

    <p>Usage: CopyTable [general options] [–starttime=X] [–endtime=Y] [–new.name=NEW] [–peer.adr=ADR] <tablename>
 Options:
 rs.class hbase.regionserver.class of the peer cluster
 specify if different from current cluster
 rs.impl hbase.regionserver.impl of the peer cluster
 starttime beginning of the time range (unixtime in millis)
 without endtime means from starttime to forever
 endtime end of the time range. Ignored if no starttime specified.
 versions number of cell versions to copy
 new.name new table's name
 peer.adr Address of the peer cluster given in the format
 hbase.zookeeer.quorum:hbase.zookeeper.client.port:zookeeper.znode.parent
 families comma-separated list of families to copy
 To copy from cf1 to cf2, give sourceCfName:destCfName.
 To keep the same name, just give "cfName"
 all.cells also copy delete markers and deleted cells
 Args:
 tablename Name of the table to copy
 Examples:
 To copy 'TestTable' to a cluster that uses replication for a 1 hour window:
 $ bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable
 --starttime=1265875194289
 --endtime=1265878794289
 --peer.adr=server1,server2,server3:2181:/hbase
 --families=myOldCf:myNewCf,cf2,cf3 TestTable
 For performance consider the following general options:
 -Dhbase.client.scanner.caching=100
 -Dmapred.map.tasks.speculative.execution=false</tablename></p>
  </li>
  <li>
    <p>Compares the data</p>

    <p>org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication类
 Usage: verifyrep [–starttime=X] [–stoptime=Y] [–families=A] <peerid> <tablename>
 Options:
 starttime beginning of the time range
 without endtime means from starttime to forever
 stoptime end of the time range
 families comma-separated list of families to copy
 Args:
 peerid Id of the peer used for verification, must match the one given for replication
 tablename Name of the table to verify
 Examples:
 To verify the data replicated from TestTable for a 1 hour window with peer #5
 $ bin/hbase org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication --starttime=1265875194289 --stoptime=1265878794289 5 TestTable</tablename></peerid></p>
  </li>
</ol>

<p>实例记录：</p>

<ol>
  <li>Export Production HBase table as following:
hbase org.apache.hadoop.hbase.mapreduce.Export ‘mytable’ /hbase_bak/mytable</li>
  <li>
    <p>Copy HDFS files to local:
hadoop fs -copyToLocal /hbase_bak/mytable /home/user/hbase_bak/mytable</p>
  </li>
  <li>
    <p>Copy the local files from production to production extension server</p>
  </li>
  <li>Copy local file to HDFS:
hadoop fs -copyFromLocal /home/user/hbase_bak/mytable /hbase_bak/mytable</li>
  <li>Create table in production extension
create ‘mytable’, {NAME=&gt;’log’, VERSION=&gt; 1}</li>
  <li>Import the HDFS files into HBase:
hbase org.apache.hadoop.hbase.mapreduce.Import ‘mytable’ /hbase_bak/mytable</li>
  <li>Verify the result:
hbase shell
count mytable</li>
</ol>

<p>Find both the row count are same in production and production extension.</p>


      <div class="readall"><a href="/blog/2014/09/27/hbase-import-export.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/eclipse-hadoop-job.html">eclipse hadoop job</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#hadoop">hadoop</a>
      </p>
    </header>
    <div class="post-main">
      <p>使用EJob提交jar
在run中添加：</p>

<pre><code>     conf.set("fs.default.name", "hdfs://192.168.241.7:9000");
      conf.set("mapred.job.tracker", "192.168.241.7:9001");
      Job job = new Job(conf, "....... my  job ......");
      try {
        File jarFile = EJob.createTempJar("bin");
        ((JobConf) job.getConfiguration()).setJar(jarFile.toString());
    } catch (IOException e) {
        throw new IOException(e);
    }
</code></pre>

<p>修改hadoop的hdfs-site.xml 关闭权限校验</p>

<pre><code> &lt;property&gt; 
      &lt;name&gt;dfs.permissions&lt;/name&gt; 
      &lt;value&gt;false&lt;/value&gt; 
 &lt;/property&gt; 
</code></pre>

<p><strong>其他解决办法：</strong></p>

<p>hdfs的权限判断十分简单，就是拿发出指令的user name和文件的user name 做比较</p>

  	private void check(INode inode, FsAction access
<pre><code>  ) throws AccessControlException {
if (inode == null) {
  return;
}
FsPermission mode = inode.getFsPermission();

if (user.equals(inode.getUserName())) { //user class
  if (mode.getUserAction().implies(access)) { return; }
}
else if (groups.contains(inode.getGroupName())) { //group class
  if (mode.getGroupAction().implies(access)) { return; }
}
else { //other class
  if (mode.getOtherAction().implies(access)) { return; }
}
throw new AccessControlException("Permission denied: user=" + user
    + ", access=" + access + ", inode=" + inode);
 	 }
}
</code></pre>

<p>在多用户提交任务时遇到Permission denied, 的原因和任务提交的过程有关。</p>

<ol>
  <li>首先提交任务的客户端会把任务相关文件打包放在hadoop.tmp.dir中，这是本地目录，需要通过本地系统权限验证。由于是临时目录直接设置成为777就行.</li>
  <li>
    <p>客户端会将任务文件打包写入hdfs的	</p>

    <pre><code>mapreduce.jobtracker.staging.root.dir + "/" + user + "/.staging" 目录，需要经过hdfs权限验证。通常可以选择两种方法解决。

1) 保持mapreduce.jobtracker.staging.root.dir为默认，将此目录chmod 777
2) 在hdfs的/user目录下建立用户目录，并且chown为该用户，相当于在hdfs下创建一个用户。
然后设置mapreduce.jobtracker.staging.root.dir为/user,  这是官方推荐的，可以看到这个属性的描述是这样写的：
The root of the staging area for users' job files In practice, this should be the directory where users' home directories are located (usually /user)。
3）有人说可以在启动任务时加入hadoop.job.ugi属性指定用户和群组。 我验证这样不行。看源码里也是直接获取
ugi = UserGroupInformation.getCurrentUser();不过看hdfs权限策略这操行应该可以设置。
</code></pre>
  </li>
</ol>


      <div class="readall"><a href="/blog/2014/09/27/eclipse-hadoop-job.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="posts">
  <section class="post">
    <header class="post-header">
      <h1 class="post-title"><a href="/blog/2014/09/27/arraylistarraylink.html">arraylist&arraylink</a></h1>
      <p class="post-meta">
        <i class="fa fa-calendar"></i>
        2014年09月27日
        <i class="space"></i>
        <i class="fa fa-tags"></i>
        <a class="post-category" href="/page/category.html#java">java</a>
      </p>
    </header>
    <div class="post-main">
      <p><strong>区别</strong>：</p>

<ol>
  <li>
    <p>array 在定义的时候必须实例化(至少申明大小)，arraylist则可以只是申明</p>

    <ul>
      <li>int[] array = new array[3]</li>
      <li>int[] array = {1,2,3}</li>
      <li>ArrayList arrayList;</li>
      <li>int[] array;则不合法</li>
    </ul>
  </li>
  <li>
    <p>Array只能存储同构对象，ArrayList则可以存储异构对象，当然object[]和使用泛型的arraylist不适用此条。</p>
  </li>
  <li>
    <p>在CRL的托管方式不一样
 Array是连续存储，Arraylist则不一定是连续存储</p>
  </li>
  <li>Array的大小是定义的时候指定的，Arraylist则可以动态扩容</li>
  <li>Array不能随意添加或删除其中的项，ArrayList则可以随意添加删除</li>
</ol>

<p><strong>相似</strong>：</p>

<ol>
  <li>都具有索引，即可以通过索引来直接添加和修改任意项</li>
  <li>所创建的对象都托管在堆中</li>
  <li>都能够对自身进行枚举（因为实现了IEnumerable接口）</li>
</ol>

<p><strong>ArrayList 源码摘要：</strong></p>

<pre><code>1. public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;  
2.         implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable  
3. {  
4.     ......  
5.   
6.     /** 
7.      * The array buffer into which the elements of the ArrayList are stored. 
8.      * The capacity of the ArrayList is the length of this array buffer. 
9.      */  
10.     private transient E[] elementData;  
11.   
12.   
13.     /** 
14.      * The size of the ArrayList (the number of elements it contains). 
15.      * 
16.      * @serial 
17.      */  
18.     private int size;  
19.    ......  
20. }  
21. 
</code></pre>

<p>底层两个属性一个object[] 一个size</p>

<ol>
  <li>ArrayList底层通过object[] 复制的方式（System.arraycopy()）来处理数组的增长</li>
  <li>当ArrayList 的容量不足时，其扩充容量的方式：先将容量扩充至当前容量的1.5倍，若还不够，则将容量扩充至当前需要的数量。</li>
</ol>

<p><strong>ArrayList与Vector的区别</strong></p>

<p>1） vector 是线程同步 的，所以它也是线程安全 的，而arraylist 是线程异步 的，是不安全的 。如果不考虑到线程的安全因素，一般用 arraylist效率比较高。</p>

<p>2） 如果集合中的元素的数目大于目前集合数组的长度时，vector 增长率为目前数组长度的100%, 而arraylist 增长率为目前数组长度的50% .如果在集合中使用数据量比较大的数据，用vector有一定的优势。</p>

<p>3） 如果查找一个指定位置的数据 ，vector和arraylist使用的时间是相同 的，都是O(1) ,这个时候使用vector和arraylist都可以。</p>

<p>而如果移动一个指定位置的数据花费的时间为O(n-i)n为总长度 ，这个时候就应该考虑到使用linklist ,因为它移动一个指定位置的数据所花费的时间为0(1),而查询一个指定位置的数据时花费的时间为0(i)。</p>

<p><strong>ArrayList和LinkedList的大致区别：</strong></p>

<ol>
  <li>ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。</li>
  <li>对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。</li>
  <li>对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 </li>
</ol>

<p><strong>ArrayList和LinkedList在性能上各有优缺点，都有各自所适用的地方，总的说来可以描述如下：</strong></p>

<ol>
  <li>对ArrayList和LinkedList而言，在列表末尾增加一个元素所花的开销都是固定的。对ArrayList而言，主要是在内部数组中增加一项，指向所添加的元素，偶尔可能会导致对数组重新进行分配；而对LinkedList而言，这个开销是统一的，分配一个内部Entry对象。</li>
  <li>在ArrayList的中间插入或删除一个元素意味着这个列表中剩余的元素都会被移动；而在LinkedList的中间插入或删除一个元素的开销是固定的。</li>
  <li>LinkedList不支持高效的随机元素访问。</li>
  <li>ArrayList的空间浪费主要体现在在list列表的结尾预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗相当的空间</li>
</ol>

<p>可以这样说：当操作是在一列数据的后面添加数据而不是在前面或中间,并且需要随机地访问其中的元素时,使用ArrayList会提供比较好的性能；当你的操作是在一列数据的前面或中间添加或删除数据,并且按照顺序访问其中的元素时,就应该使用LinkedList了。</p>


      <div class="readall"><a href="/blog/2014/09/27/arraylistarraylink.html" id="post-readall">阅读全文&nbsp;<i class="fa fa-chevron-right"></i></a></div>
    </div>
  </section>
</div>

<div class="pagination">
  
  
  <a class="pagination-item newer" href="/page/2"><i class="fa fa-arrow-left"></i>&nbsp;&nbsp;上一页</a>
  
    
  
  <a class="pagination-item older" href="/page/4">下一页&nbsp;&nbsp;<i class="fa fa-arrow-right"></i></a>
  
</div>
    <footer>Copyright&nbsp;&copy;&nbsp;2014 <a href="index.html">willgo</a><br/><i class="fa fa-cogs" style="color:blueviolet;">&nbsp;</i>Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a></footer>
    </div>
  </div>    
  <div id="top"><a id="rocket" href="javascript:;" title="返回顶部"><i></i></a></div>
  
</body>
</html>